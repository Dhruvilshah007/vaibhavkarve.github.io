#+title: Multiprocessing in Python
#+options: toc:2 H:2
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/stylesheet.css" />
#+subtitle: [[file:index.org][Home]]

- Python documentation :: [[https://docs.python.org/3/library/multiprocessing.html][multiprocessing module]]

* Introduction
The =multiprocessing= module (MP) spawns sub-processes insteads of threads.  Can be
used for data parallelism -- parallelizing the execution of a function
accross multiple input values by distributing the data accross
processes.

* Start methods
Can be set as follows.
#+name: set-start-method
#+attr_latex: :options label= (python3.8) (scratch) <<set-start-method>>
#+begin_src python :exports code :eval none
  import multiprocessing as mp

  def foo(q):
      pass

  if __name__ == '__main__':
      # using get_context() is preferred over set_start_method().
      ctx = mp.get_context('spawn')  # mp has custom Context object
				     # types.
      q = ctx.Queue()
      p = ctx.Process(target=foo, args=(q,))
#+end_src



=set_start_method()= should not be used more than once in the program.

** =spawn=
   Parent process starts a fresh python interpreter each time. This is
   the slowest option. Inherits only those objects that are needed by
   the =multiprocessing.Process.run= method.

** =fork=
   Parent process forks the python interpreter using =os.fork()=. All
   resources of the parent are inherited by the child process. This is
   faster then =spawn=.

   "Not safe if used on a multi-threading process" (I think this means
   that this method should not be used if we are also using the
   =threading= module?). Overall the fork start method can lead to
   crashes of the subprocess so it is unsafe.

   This is available on Unix only.

** =forkserver=
   When the program starts, using this method, a server process is
   also started. The fork server can fork a new process every time it
   is requested. The fork process server is single-threaded and so it
   is safely uses =os.fork()=. No unnecessary resources are inherited
   from the parent process.

   Similar to =fork=, this is available on Unix only.

** Verdict
   I will be using =forkserver= for my programs.

* Communication between processes
  MP allows exchange of objects between processes.
** Queue
Use =mp.Queue= instead of =queue.Queue=.

Steps:
1. Create a queue using =q = mp.Queue()=.
2. =q.put([1, 'a', 2])= puts the list =[1, 'a', 2]= into the queue.
3. =q.get()= retrieves whatever was put in the queue (I think it
   retrieves in FIFO order?). This can be using in conjunction with
   another function as in =len(q.get())= to get the length of our
   list.
#+name: queue-example
#+attr_latex: :options label= (python3.8) (scratch) <<queue-example>>
#+begin_src python :results output pp :exports both :session
import multiprocessing as mp

q = mp.Queue()
print(q)
q.put([1, 'a', 2])
print(len(q.get()))
#+end_src

#+RESULTS: queue-example
: <multiprocessing.queues.Queue object at 0x7ff4e73a86d0>
: 3

*** Putting many queues inside(?) a single process
1. Start a process using =p = mp.Process(target=putter, arg=q)=, where
   =putter= puts objects into the queue =q=.
2. Start the process: =p.start()=.
3. Intermediate action like requesting things from the queue.
4. Join after process termination: =p.join()=.

#+name: process-queues
#+attr_latex: :options label= (python3.8) (scratch) <<process-queues>>
#+begin_src python :session :results output
def putter(q: mp.queues.Queue, value):
    q.put(value)

if __name__ == '__main__':
    q: mp.queues.Queue = mp.Queue()

    p: mp.Process = mp.Process(target=putter, args=(q, [42, None, 'hello']))
    
    p.start()
    print(q.get())    # prints "[42, None, 'hello']"
    # print(q.get)    # Running it again blocks the process for some reason.
    p.join()
#+end_src

#+RESULTS: process-queues
: [42, None, 'hello']
